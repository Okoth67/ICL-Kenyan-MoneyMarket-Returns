{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24064cd3-9935-4174-a93d-e846a96cd76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bbollo\\AppData\\Local\\anaconda3\\envs\\wekeza\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers and GPU quantization are unavailable.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): lora.Linear(\n",
       "            (base_layer): Conv1D(nf=2304, nx=768)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=2304, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (c_proj): lora.Linear(\n",
       "            (base_layer): Conv1D(nf=768, nx=768)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): lora.Linear(\n",
       "            (base_layer): Conv1D(nf=768, nx=3072)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the model and its tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_path = \"./distilgpt2-wekeza-finetuned_v3_lora\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "264539fc-9f18-45be-8a77-a388d68750db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text gen function\n",
    "def generate_output(prompt, max_new_tokens=100):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf5ba18-3002-490b-8ed4-2c9894867416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ICL Prediction ===\n",
      "\n",
      "Below are examples of returns for Kenyan Money Market Funds:\n",
      "\n",
      "Example 1:\n",
      "Fund: NCBA Money Market Fund\n",
      "Return: 13.5%\n",
      "\n",
      "Example 2:\n",
      "Fund: Sanlam Money Market Fund\n",
      "Return: 13.3%\n",
      "\n",
      "Example 3:\n",
      "Fund: CIC Money Market Fund\n",
      "Return: 12.5%\n",
      "\n",
      "Example 4:\n",
      "Money Market Fund\n",
      "Return: 12.5%\n",
      "\n",
      "Example 5:\n",
      "Money Market Fund\n",
      "Return: 12.5%\n",
      "\n",
      "Example 6:\n",
      "Money Market Fund\n",
      "Return: 12.5%\n",
      "\n",
      "Example 7:\n",
      "Money Market Fund\n",
      "Return: 12.5%\n",
      "\n",
      "Example 8:\n",
      "Money Market Fund\n",
      "Return: 12.5%\n",
      "\n",
      "Example 9:\n",
      "Money Market Fund\n",
      "Return: 12.5%\n"
     ]
    }
   ],
   "source": [
    "# ICL Test Example: Kenya Money Market Fund Returns as at 28th July\n",
    "icl_prompt = \"\"\"\n",
    "Below are examples of returns for Kenyan Money Market Funds:\n",
    "\n",
    "Example 1:\n",
    "Fund: NCBA Money Market Fund\n",
    "Return: 13.5%\n",
    "\n",
    "Example 2:\n",
    "Fund: Sanlam Money Market Fund\n",
    "Return: 13.3%\n",
    "\n",
    "Example 3:\n",
    "Fund: CIC Money Market Fund\n",
    "Return:\"\"\"\n",
    "\n",
    "# Generate output based on prompt with examples\n",
    "icl_output = generate_output(icl_prompt)\n",
    "print(\"=== ICL Prediction ===\")\n",
    "print(icl_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b6db8ba-bd07-46d6-847c-85d7ff06d03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Non-ICL Prediction ===\n",
      "What is the return of CIC Money Market Fund?\n",
      "\n",
      "### Response:\n",
      "CIC Money Market Fund returns annually from CIC Money Market Fund to CIC Money Market Fund. CIC Money Market Fund returns annually from CIC Money Market Fund to CIC Money Market Fund. CIC Money Market Fund returns annually from CIC Money Market Fund to CIC Money Market Fund. CIC Money Market Fund returns annually from CIC Money Market Fund to CIC Money Market Fund. CIC Money Market Fund returns annually from CIC Money Market Fund to\n"
     ]
    }
   ],
   "source": [
    "#comparison\n",
    "no_icl_prompt = \"What is the return of CIC Money Market Fund?\"\n",
    "no_icl_output = generate_output(no_icl_prompt)\n",
    "print(\"=== Non-ICL Prediction ===\")\n",
    "print(no_icl_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddeaa1db-ed08-48ce-8746-46ad4d86790b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ICL Prediction (Natural Language Style) ===\n",
      "\n",
      "Here are some summaries of returns from popular Kenyan money market funds:\n",
      "\n",
      "- The NCBA Money Market Fund posted an annual return of 13.5% this quarter.\n",
      "- Sanlam’s Money Market Fund achieved a yield of 13.3% during the same period.\n",
      "- CIC Money Market Fund recorded a return of\n",
      "12.5% in 2015.\n",
      "- CIC Money Market Fund returns were held quarterly.\n",
      "### Response:\n",
      "CIC Money Market Fund returns are typically held quarterly, but quarterly returns typically reflect quarterly returns. Annual returns typically reflect quarterly returns. Annual returns typically reflect quarterly returns. Annual returns typically reflect quarterly returns. Annual returns typically reflect quarterly returns. Annual returns typically reflect quarterly returns. Annual returns typically reflect quarterly returns. Annual returns typically reflect quarterly returns. Annual returns typically reflect quarterly returns. Annual\n"
     ]
    }
   ],
   "source": [
    "#trying new prompt\n",
    "icl_prompt_natural = \"\"\"\n",
    "Here are some summaries of returns from popular Kenyan money market funds:\n",
    "\n",
    "- The NCBA Money Market Fund posted an annual return of 13.5% this quarter.\n",
    "- Sanlam’s Money Market Fund achieved a yield of 13.3% during the same period.\n",
    "- CIC Money Market Fund recorded a return of\n",
    "\"\"\"\n",
    "\n",
    "icl_output_natural = generate_output(icl_prompt_natural)\n",
    "print(\"=== ICL Prediction (Natural Language Style) ===\")\n",
    "print(icl_output_natural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b5cf55-d979-4983-8340-691f49af0886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
